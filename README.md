### Setting Up Your Environment
1. Install "Django", "django-filter" and "djangorestframework" into your virtual environment using pip or conda. This is how you packages list should look like after doing the 3 installs:
  -Package             Version                                                                                                                
  -asgiref             3.9.1
  -Django              5.2.6
  -django-filter       25.1                                                                                                                   
  -djangorestframework 3.16.1
  -pip                 25.2                                                                                                                   
  -sqlparse            0.5.3
  -tzdata              2025.2 

2. Clone the repo, there is several methods to this and I would recommend doing it by url. Activate you virtual enironment if you're gonna use it.
3. In your terminal, navigate to /claims-management/claims_manage/ - this is where the magic happens
4. Load database migrations by running the following command in your terminal "python manage.py migrate"
5. If you want to use the default data, the one given in the challenege page, run "python manage.py load_db" this loads the data into the table
  - If you want to APPEND data to the tables- "python manage.py load_db --append --details-file [filepath equivalent to details file] --list-file [filepath equivalent to list file]
  - If you want to REPLACE data - "python manage.py load_db --details-file [filepath equivalent to details file] --list-file [filepath equivalent to list file]" 
  - Note how the "--append" option goes away
#### The server is ready to run!!!
6. Now type "python manage.py runserver" in your terminal and follow the link it gives you or type in your browser -"http://127.0.0.1:8000/", you can also run "python manage.py runserver [port#]" if for whatever reason 8000 is occupied.

### Some notes about the design of the project and future work
* The frontend was meant designed as three-part modular structure. The first row holds the search bar and the filters. The second holds the table. And the third holds the details, notes and flags. The search and filtering structures are very standard. You simply type into the search bar and the table holds the result of the search. There is the possibility of a partial name search (the ID search has to be EXACT for it to work), this is much more efficient if you look up by just a first or just a last name. This could be useful for when the user does not quite remember a full name. The filtering is also very straigthforward. The button opens a modal, the user can choose their filters and then apply them. The user HAS to press the apply filter button in order for them to work. When they are applied, there will be a button that appears to clear them. The same applies with the search, although the user can also delete the search bar input and it will clear it. The user must press enter or press the search button for the search to apply. The django-filter was especially helpful for the querying of the filters
* The table, the second row, is where all of the information is stored, whether it is searched or filtered. The user is allowed to click the rows to open their details and their notes and flags. I used HTMX's hx-get as triggers for this, they query the database with a GET endpoint, and the details and notes and flags are sprung to life. There is also a red highlight the rows that are flagged.
* The last row is where all of the details reside. The user is allowed to create, delete and modify notes. And the flags also. The timestamps for the flags and the notes only appear if they exist. The server dictates the time at which they created, using the signals file in the claims_app folder. This useful as you generally want the server to be holder of absolute truth, and you don't have worry about syncing them. The endpoint used for the handling of the notes and flags' timestamps only require the details of such flag and note, the signal also takes care of updating the table with the appropriate information. Then the client uses the response from the POST/PATCH methods to update the frontend with the times at which the server received them.
* I used the Alpinejs global store to keep the general state of the page, particularly for what are the details that are supposed to be loaded in the details. The initailizing table query loads a lot of the data, and this data is stored so that it can also be referenced when the row is selected (selectedPatient). Then the hx-get loads the additionalDetails for the consumption at the details section of the page.
* For the backend, I decided to use 3 tables, one for the claim list, one for the details and another for the Notes and Flags. I originally tried to do this with only the former two tables, but after a bit of research I decided to add the third. This was mainly so that the claims didn't carry the extra fields for the notes and stamps, as this might be a waste of storage. This obviously means that I had to a special sort of join so that the response were appended the correct information about the flag status and the claim details (the query that updates the rows shown in the table have the flag appended to them, the query that shows the details have the note, its stamp and the flag stamp). I encourage you to look around the views and serializer to see just how it was done. It was very new to me and I have to admit I was excited as to how elegant it resulted.
* This is a very high level explanation as to my approach, the comments in the files will be a little more in depth.
* There is some work that still needs to be done, I will admit. Not just the addition of features, like the different users and the stats dashboard. But also some improvements to how the elements are presented in the page. Like the clear filtering button, it takes over too much of the table and it minimizes the table too much. Also I can add input verification to the filters and allow the user to filter by the presence of flags. Either way, I do plan to keep working on this (after the review period), it was a great learning experience and there is still so much more that can be done!
* If you got this far, thank you!
